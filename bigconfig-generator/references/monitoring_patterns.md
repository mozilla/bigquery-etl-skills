# Bigeye Monitoring Patterns

> **⚠️ IMPORTANT:** This reference may become outdated as Bigeye monitoring evolves. For authoritative, up-to-date information, always refer to:
> - **Official bigConfig docs:** https://mozilla.github.io/bigquery-etl/reference/bigconfig/ (docs/reference/bigconfig.md)
> - **Bigeye intro:** https://mozilla.github.io/data-docs/cookbooks/data_monitoring/intro.html
> - **Bigeye documentation:** https://docs.bigeye.com/docs/bigconfig
>
> This file provides **workflow guidance and common patterns** but should not be considered the source of truth for bigConfig syntax or available metrics.

This reference documents common monitoring configurations and workflows used in Mozilla's bigquery-etl repository with Bigeye data quality monitoring.

## Overview

Bigeye monitoring is configured through:
1. **metadata.yaml** - High-level monitoring enablement and settings
2. **bigconfig.yml** - Detailed metric definitions (auto-generated from metadata.yaml)
3. **bigeye_custom_rules.sql** - Custom SQL validation rules (optional)

## Metadata.yaml Monitoring Configuration

### Basic Monitoring Enablement

```yaml
monitoring:
  enabled: true
```

This minimal configuration enables basic monitoring. The `./bqetl monitoring update` command will generate appropriate bigconfig.yml based on table structure.

### Freshness Monitoring

Monitor when data was last updated:

```yaml
monitoring:
  enabled: true
  freshness:
    enabled: true
    blocking: false  # Set to true if freshness failures should block pipelines
```

**When to use:**
- Tables updated on a schedule (daily, hourly)
- Critical tables where staleness indicates pipeline failures
- Set `blocking: true` for tables where stale data should fail CI/CD

### Volume Monitoring

Monitor row count changes:

```yaml
monitoring:
  enabled: true
  volume:
    enabled: true
    blocking: false  # Set to true if volume anomalies should block pipelines
```

**When to use:**
- Tables with expected row count patterns
- Detect sudden drops (data loss) or spikes (duplicate data)
- Set `blocking: true` for critical tables

### Partition Column Configuration

For views or tables where Bigeye needs explicit partition column:

```yaml
monitoring:
  enabled: true
  partition_column: submission_date  # or null for non-partitioned
  partition_column_set: true
```

**When to use:**
- **Required for views** - Bigeye cannot auto-detect partition columns on views
- Set `partition_column: null` for non-partitioned views
- Set `partition_column_set: true` to indicate explicit configuration

### Collection and Notifications

Group related tables and configure alerting:

```yaml
monitoring:
  enabled: true
  collection: "Subscription Platform"
```

**Common collections:**
- "Operational Checks" - Standard operational monitoring
- "Subscription Platform" - SubPlat team tables
- "Test" - Testing/development monitoring

Collections are defined in bigconfig.yml with notification channels (Slack, email).

### Complete Example

```yaml
monitoring:
  enabled: true
  freshness:
    enabled: true
    blocking: true
  volume:
    enabled: true
    blocking: false
  partition_column: submission_date
  partition_column_set: true
  collection: "Subscription Platform"
```

## Bigconfig.yml Structure

Auto-generated by `./bqetl monitoring update` command based on metadata.yaml settings.

### Saved Metrics (Defined in sql/bigconfig.yml)

Common reusable metrics defined in root bigconfig.yml:

**`is_not_null`** - Column must be 100% non-null:
```yaml
saved_metric_id: is_not_null
```

**`is_99_percent_not_null`** - Column can be up to 1% null:
```yaml
saved_metric_id: is_99_percent_not_null
```

**`is_unique`** - Column values must be unique (no duplicates):
```yaml
saved_metric_id: is_unique
```

**`is_valid_client_id`** - Column must contain valid UUIDs:
```yaml
saved_metric_id: is_valid_client_id
```

**`is_99_percent_valid_normalized_channel`** - 99%+ values in allowed list:
```yaml
saved_metric_id: is_99_percent_valid_normalized_channel
```

**`is_2_char_len`** - String length must be exactly 2 characters:
```yaml
saved_metric_id: is_2_char_len
```

**`freshness`** - Table freshness monitoring:
```yaml
saved_metric_id: freshness
```

**`freshness_fail`** - Freshness with failure state (blocking):
```yaml
saved_metric_id: freshness_fail
```

**`volume`** - Table volume monitoring:
```yaml
saved_metric_id: volume
```

**`volume_fail`** - Volume with failure state (blocking):
```yaml
saved_metric_id: volume_fail
```

**`composite_key_uniqueness_2_column`** - Two-column composite key uniqueness:
```yaml
saved_metric_id: composite_key_uniqueness_2_column
```

**`composite_key_uniqueness_3_column`** - Three-column composite key uniqueness:
```yaml
saved_metric_id: composite_key_uniqueness_3_column
```

### Tag Deployments

Tag deployments apply metrics to columns using selectors:

```yaml
tag_deployments:
- collection:
    name: 'Operational Checks'
    notification_channels:
    - slack: '#de-bigeye-triage'
  deployments:
  - column_selectors:
    - name: moz-fx-data-shared-prod.moz-fx-data-shared-prod.dataset.table.column_name
    metrics:
    - saved_metric_id: is_not_null
      rct_overrides:
      - submission_date
```

**Column selector patterns:**
- Specific column: `project.project.dataset.table.column_name`
- All columns: `project.project.dataset.table.*`

**rct_overrides:**
- Row Creation Time overrides - specify partition column for partitioned tables
- Common value: `submission_date`

### Table Deployments

Table deployments apply metrics to specific tables:

```yaml
table_deployments:
- collection:
    name: 'Subscription Platform'
    notification_channels:
    - slack: '#de-bigeye-triage'
    - email: 'team@mozilla.com'
  deployments:
  - fq_table_name: moz-fx-data-shared-prod.moz-fx-data-shared-prod.dataset.table
    columns:
    - column_name: id
      metrics:
      - saved_metric_id: is_unique
        rct_overrides:
        - valid_from
```

### Row Creation Times

Explicit partition column configuration:

```yaml
row_creation_times:
  column_selectors:
  - name: moz-fx-data-shared-prod.moz-fx-data-shared-prod.dataset.table.submission_date
```

## Common Monitoring Patterns

### Pattern 1: Basic Table Monitoring (Freshness + Volume)

**Use case:** Daily updated tables with no special validation needs

**metadata.yaml:**
```yaml
monitoring:
  enabled: true
  freshness:
    enabled: true
  volume:
    enabled: true
```

**Generated bigconfig.yml:**
- Freshness check on table
- Volume check on table
- Uses default schedule (13:00 UTC)

### Pattern 2: Critical Table with Blocking Checks

**Use case:** Production-critical tables where failures should halt deployments

**metadata.yaml:**
```yaml
monitoring:
  enabled: true
  freshness:
    enabled: true
    blocking: true
  volume:
    enabled: true
    blocking: true
  collection: "Operational Checks"
```

**Result:**
- Uses `freshness_fail` and `volume_fail` metrics
- Failures will fail CI/CD pipeline
- Alerts sent to collection's notification channels

### Pattern 3: Column-Level Validation

**Use case:** Tables with columns requiring specific validation (uniqueness, null checks)

**metadata.yaml:**
```yaml
monitoring:
  enabled: true
  collection: "Subscription Platform"
```

**Manual bigconfig.yml customization needed:**
```yaml
tag_deployments:
- collection:
    name: 'Subscription Platform'
  deployments:
  - column_selectors:
    - name: moz-fx-data-shared-prod.moz-fx-data-shared-prod.dataset.table.client_id
    metrics:
    - saved_metric_id: is_valid_client_id
      rct_overrides:
      - submission_date
  - column_selectors:
    - name: moz-fx-data-shared-prod.moz-fx-data-shared-prod.dataset.table.id
    metrics:
    - saved_metric_id: is_unique
      rct_overrides:
      - submission_date
```

### Pattern 4: View Monitoring with Explicit Partition

**Use case:** Views that reference partitioned tables

**metadata.yaml:**
```yaml
monitoring:
  enabled: true
  partition_column: submission_date
  partition_column_set: true
  freshness:
    enabled: true
```

**Workflow:**
1. Enable monitoring in metadata.yaml
2. Run `./bqetl monitoring update` to generate bigconfig.yml
3. Deploy with `./bqetl monitoring deploy` - this sets partition column in Bigeye

### Pattern 5: Custom SQL Validation Rules

**Use case:** Complex business logic validation

**Create bigeye_custom_rules.sql:**
```sql
-- {
--   "name": "Table custom validation",
--   "alert_conditions": "value",
--   "range": {
--     "min": 0,
--     "max": 1
--   },
--   "collections": ["Operational Checks"],
--   "owner": "team@mozilla.com",
--   "schedule": "Default Schedule - 13:00 UTC"
-- }
SELECT
  ROUND((COUNTIF(NOT condition)) / COUNT(*) * 100, 2) AS perc
FROM
  `{{ project_id }}.{{ dataset_id }}.{{ table_name }}`;
```

**JSON configuration options:**
- `name` - Rule name displayed in Bigeye
- `alert_conditions` - "value" or "count"
- `range.min/max` - Acceptable value range
- `collections` - Which collection(s) to add rule to
- `owner` - Email for notifications
- `schedule` - Named schedule from Bigeye

## Lookback Windows

Control how far back Bigeye looks for data:

```yaml
lookback:
  lookback_window:
    interval_type: DAYS
    interval_value: 28
  lookback_type: DATA_TIME
```

**Common patterns:**
- `interval_value: 0` - Only check latest partition (default for incremental tables)
- `interval_value: 7` - Check last 7 days
- `interval_value: 28` - Check last 28 days (good for tables with sporadic updates)

**When to customize:**
- Tables with infrequent updates (use longer lookback)
- Historical backfills (use longer lookback during backfill)
- High-volume tables (use 0 to avoid scanning too much data)

## Deployment Workflow

### 1. Enable Monitoring

Edit metadata.yaml:
```yaml
monitoring:
  enabled: true
  freshness:
    enabled: true
  volume:
    enabled: true
```

### 2. Generate bigconfig.yml

```bash
./bqetl monitoring update dataset.table
```

This creates/updates the bigconfig.yml file based on metadata.yaml settings.

### 3. Customize (Optional)

Edit bigconfig.yml to add:
- Column-level metrics
- Custom thresholds
- Lookback windows
- Additional collections

### 4. Validate

```bash
./bqetl monitoring validate dataset.table
```

Checks bigconfig.yml syntax and configuration.

### 5. Deploy

```bash
./bqetl monitoring deploy dataset.table --dry-run
# Review changes, then deploy:
./bqetl monitoring deploy dataset.table
```

Requires `BIGEYE_API_KEY` environment variable.

### 6. Run Checks (Optional)

```bash
./bqetl monitoring run dataset.table
```

Manually triggers monitoring checks for testing.

## Best Practices

### When to Enable Monitoring

**Always enable:**
- Production tables used in dashboards/reports
- Tables with SLAs or freshness requirements
- Critical pipeline outputs

**Consider enabling:**
- Development/staging tables for testing monitoring configs
- Tables with known data quality issues

**Skip monitoring:**
- Temporary/scratch tables
- One-time analysis tables
- Tables with no consumers

### Freshness vs Volume

**Freshness** - Use when:
- Table has scheduled updates (daily, hourly)
- Staleness indicates pipeline failure
- Consumers need timely data

**Volume** - Use when:
- Table has predictable row counts
- Need to detect data loss (sudden drops)
- Need to detect duplicate data (sudden spikes)

### Blocking vs Non-Blocking

**Blocking (`blocking: true`)** - Use when:
- Failures must halt deployments
- Table is production-critical
- False positives are rare

**Non-Blocking (`blocking: false`)** - Use when:
- Failures should alert but not block
- Table is still stabilizing
- False positives are expected

### Collections

**Use consistent collection names:**
- Group related tables by team/product
- Configure notification channels once per collection
- Makes alert management easier

**Common collections:**
- Team-specific: "Subscription Platform", "Ads Team", "Growth Team"
- Function-specific: "Operational Checks", "Data Quality"
- Environment-specific: "Test", "Staging"

### Custom Rules

**When to use custom SQL rules:**
- Business logic validation (e.g., "revenue > 0")
- Cross-column validation (e.g., "start_date < end_date")
- Format validation (e.g., version string patterns)
- Percentage-based thresholds

**Custom rule best practices:**
- Return percentage (0-100) for "value" alert conditions
- Return count for "count" alert conditions
- Use Jinja variables: `{{ project_id }}`, `{{ dataset_id }}`, `{{ table_name }}`
- Set appropriate min/max ranges
- Document the rule's purpose in comments

## Troubleshooting

### Bigconfig validation errors

**Error:** "Duplicate deployments"
- **Cause:** Same column selector appears multiple times
- **Fix:** Consolidate metrics under single deployment

**Error:** "Invalid metric"
- **Cause:** Referencing non-existent saved_metric_id
- **Fix:** Check sql/bigconfig.yml for available saved metrics

### Deployment failures

**Error:** "Bigeye API token needs to be set"
- **Fix:** Set `BIGEYE_API_KEY` environment variable

**Error:** "Table does not exist in Bigeye"
- **Cause:** Table not yet ingested by Bigeye
- **Fix:** Wait for Bigeye's next schema sync, or manually sync in Bigeye UI

**Error:** "Partition column does not exist"
- **Cause:** metadata.yaml specifies non-existent column
- **Fix:** Verify partition_column matches actual column name in schema.yaml

### Monitoring check failures

**False positives on freshness:**
- Check if table actually updated (query BigQuery directly)
- Verify partition_column is set correctly
- Check if Bigeye's schedule aligns with table's update schedule

**False positives on volume:**
- Normal for tables with varying row counts
- Consider using longer lookback window
- Consider disabling volume checks for this table
